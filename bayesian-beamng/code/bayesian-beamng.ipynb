{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "non-broadcastable output operand with shape (100,) doesn't match the broadcast shape (100,100)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 65\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ei\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# Calculate the Expected Improvement (EI) at each test point\u001b[39;00m\n\u001b[0;32m---> 65\u001b[0m ei \u001b[38;5;241m=\u001b[39m \u001b[43mexpected_improvement\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# Plot the results\u001b[39;00m\n\u001b[1;32m     68\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n",
      "Cell \u001b[0;32mIn[10], line 54\u001b[0m, in \u001b[0;36mexpected_improvement\u001b[0;34m(X, X_sample, Y_sample, gp, xi)\u001b[0m\n\u001b[1;32m     51\u001b[0m imp \u001b[38;5;241m=\u001b[39m mu \u001b[38;5;241m-\u001b[39m mu_sample_opt \u001b[38;5;241m-\u001b[39m xi\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# Normalize the improvement by the uncertainty\u001b[39;00m\n\u001b[0;32m---> 54\u001b[0m Z \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdivide\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimp\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msigma\u001b[49m\u001b[38;5;241;43m!=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# Expected Improvement calculation using the CDF and PDF of normal distribution\u001b[39;00m\n\u001b[1;32m     57\u001b[0m ei \u001b[38;5;241m=\u001b[39m imp \u001b[38;5;241m*\u001b[39m norm\u001b[38;5;241m.\u001b[39mcdf(Z) \u001b[38;5;241m+\u001b[39m sigma \u001b[38;5;241m*\u001b[39m norm\u001b[38;5;241m.\u001b[39mpdf(Z)\n",
      "\u001b[0;31mValueError\u001b[0m: non-broadcastable output operand with shape (100,) doesn't match the broadcast shape (100,100)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n",
    "from scipy.stats import norm\n",
    "\n",
    "# 3 observations of a single parameter (x) and their corresponding output (y)\n",
    "X = np.array([[1], [3], [5]])  # 1D input data (shape is (n_samples, 1))\n",
    "y = np.array([2, 3, 5])  # Observations (outputs)\n",
    "\n",
    "# Define the kernel for the GP: constant kernel times RBF kernel\n",
    "kernel = C(1.0, (1e-3, 1e3)) * RBF(length_scale=1.0, length_scale_bounds=(1e-2, 1e2))\n",
    "\n",
    "# Create a Gaussian Process model\n",
    "gp = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10)\n",
    "\n",
    "# Fit the model to the data\n",
    "gp.fit(X, y)\n",
    "\n",
    "# Generate test data for prediction (over a grid of points for visualization)\n",
    "X_test = np.linspace(0, 6, 100).reshape(-1, 1)  # Input space for predictions\n",
    "\n",
    "# Predict using the GP model\n",
    "y_pred, sigma = gp.predict(X_test, return_std=True)  # Get both mean and uncertainty (std)\n",
    "\n",
    "# Define Expected Improvement (EI) acquisition function\n",
    "def expected_improvement(X, X_sample, Y_sample, gp, xi=0.01):\n",
    "    \"\"\"\n",
    "    Computes the EI at points X based on existing samples X_sample and Y_sample\n",
    "    from the Gaussian process model.\n",
    "\n",
    "    Arguments:\n",
    "    X -- Points at which EI shall be computed (test points)\n",
    "    X_sample -- Sampled input points (observations)\n",
    "    Y_sample -- Corresponding observed function values\n",
    "    gp -- A fitted GaussianProcessRegressor model\n",
    "    xi -- Exploitation-exploration trade-off parameter\n",
    "\n",
    "    Returns:\n",
    "    EI values for the test points X.\n",
    "    \"\"\"\n",
    "    mu, sigma = gp.predict(X, return_std=True)\n",
    "    \n",
    "    # Ensure sigma is reshaped to avoid dimension mismatch\n",
    "    sigma = sigma.reshape(-1, 1)\n",
    "    \n",
    "    # Best observed value so far (exploitation target)\n",
    "    mu_sample_opt = np.max(Y_sample)\n",
    "\n",
    "    # Compute the improvement\n",
    "    imp = mu - mu_sample_opt - xi\n",
    "    \n",
    "    # Normalize the improvement by the uncertainty\n",
    "    Z = np.divide(imp, sigma, out=np.zeros_like(imp), where=sigma!=0)\n",
    "\n",
    "    # Expected Improvement calculation using the CDF and PDF of normal distribution\n",
    "    ei = imp * norm.cdf(Z) + sigma * norm.pdf(Z)\n",
    "    \n",
    "    # EI should be 0 where sigma is 0 to prevent NaN values\n",
    "    ei[sigma == 0.0] = 0.0\n",
    "    \n",
    "    return ei\n",
    "\n",
    "# Calculate the Expected Improvement (EI) at each test point\n",
    "ei = expected_improvement(X_test, X, y, gp)\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot the GP mean prediction\n",
    "plt.plot(X_test, y_pred, 'b-', label='GP mean')\n",
    "\n",
    "# Plot the uncertainty (confidence interval)\n",
    "plt.fill_between(X_test.ravel(), \n",
    "                 y_pred - 1.96 * sigma, \n",
    "                 y_pred + 1.96 * sigma, \n",
    "                 alpha=0.2, color='blue', label='95% confidence interval')\n",
    "\n",
    "# Plot the original observations\n",
    "plt.scatter(X, y, c='r', s=100, zorder=10, label='Observations')\n",
    "\n",
    "# Plot the acquisition function (scaled for visualization)\n",
    "plt.plot(X_test, ei, 'g--', label='Acquisition (EI)')\n",
    "\n",
    "plt.title('Gaussian Process Regression with Acquisition Function')\n",
    "plt.xlabel('Parameter')\n",
    "plt.ylabel('Observation / Acquisition Value')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bayesian-beamng",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
